# üìö Gemini Long-Context Chat (DocuChat AI)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?logo=streamlit&logoColor=white)
![Google Gemini](https://img.shields.io/badge/Gemini%202.5%20Flash-8E75B2?logo=google&logoColor=white)
![Status](https://img.shields.io/badge/Status-Stable-brightgreen)

## üìå Overview
**DocuChat AI** is a streamlined document analysis tool that leverages the massive **Context Window** of Google's Gemini 2.5 Flash model. 

Unlike traditional RAG (Retrieval-Augmented Generation) systems that chunk documents into small pieces, this application takes a **"Full Context" approach**. It feeds the *entire* content of your uploaded documents (PDFs, TXT, MD) directly into the model's memory for every query.

**Why this approach?**
* **Zero Information Loss:** No risk of missing context due to poor chunking or retrieval algorithms.
* **Global Reasoning:** The AI understands the document as a whole, connecting information from Page 1 to Page 100.
* **Simplicity:** No Vector Databases (Pinecone/Chroma) or Embedding models required.

## ‚ú® Key Features

### üß† Full Context "Brute Force"
Leveraging Gemini's ability to handle millions of tokens, we send the **entire dataset** + **conversation history** with every prompt. This ensures the highest possible accuracy for complex queries involving multiple parts of a document.

### üìÇ Multi-Format Support
* **PDFs:** Processed as binary streams for accurate parsing.
* **Text & Markdown:** Native handling with clear metadata tagging (`=== START OF FILE ===`) to help the AI distinguish sources.

### üìä Token Awareness
Since this method is token-heavy, the app includes a built-in **Token Counter**. It transparently displays exactly how many tokens are being sent to Google's API for every message, helping you monitor usage.

### ‚ö° Professional UX
* **Real-time Streaming:** Responses are streamed character-by-character.
* **Status Indicators:** Visual feedback for every background process (Parsing -> Synchronizing Memory -> Token Calculation -> Generating).
* **Safety Rails:** Configured with `BLOCK_ONLY_HIGH` thresholds to ensure valid documents aren't blocked by over-sensitive filters.

## üõ†Ô∏è Tech Stack
* **Engine:** Google Gemini 2.5 Flash (via `google-genai` SDK).
* **Interface:** Streamlit.
* **Language:** Python 3.9+.

## ‚ö†Ô∏è Limitations (The "Cost" of Full Context)
While this method provides superior accuracy, it comes with trade-offs:
1.  **Token Usage:** Sending entire documents repeatedly consumes a high number of tokens.
2.  **Latency:** Response times may increase linearly with the size of uploaded documents.
3.  **Best Use Case:** Ideal for specific tasks (analyzing 1-5 papers/contracts) rather than querying massive libraries (1000+ books).

## üì¶ Installation

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/viochris/Gemini-Long-Context-Chat.git
    cd Gemini-Long-Context-Chat
    ```

2.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Run the Application**
    ```bash
    streamlit run app.py
    ```

## üöÄ Usage Guide

1.  **Get API Key:** Obtain your free API Key from [Google AI Studio](https://aistudio.google.com/).
2.  **Configure:** Enter the key in the sidebar.
3.  **Upload:** Drag and drop your PDF, TXT, or MD files.
4.  **Chat:** Ask questions like *"Summarize the methodology in the PDF"* or *"Compare the conclusions of these two text files."*

## üì∑ Gallery

### 1. Initial State & Security
![Initial State](assets/01_initial_state.png)
*Upon launching, the application locks functionality until a valid Google API Key is securely provided in the sidebar.*

### 2. Interactive Document Chat
![Main Chat UI](assets/02_main_chat_ui.png)
*Once configured, users can upload documents and engage in a natural language conversation. The AI provides detailed answers grounded in the file content.*

### 3. AI Orchestration (In-Progress)
![Processing Step](assets/03_process_running.png)
*The system transparently shows the "thinking" steps in real-time: parsing documents, synchronizing memory, and contextualizing the query.*

### 4. Completion & Token Analysis
![Process Complete](assets/04_process_complete.png)
*Once processing is complete, the status turns green ("Insight Generated") and displays the exact **Input Token Count**, giving users full visibility into API usage.*

---
**Author:** [Silvio Christian, Joe]
*"Sometimes, the best retrieval strategy is to just read everything."*
